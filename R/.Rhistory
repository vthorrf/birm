### Assemble data list====
mon.names  <- "LP"
n = length(x)
H = 1000000
basemu = rnorm(H, mean(x), diff(range(x)))
basesg = rnorm(H, sd(x), 5)
alpha = alpha
parm.names <- as.parm.names(list( V=rep(0,1),
mu=rep(0,n),
sigma=rep(0,n) ))
pos.V     <- grep("V", parm.names)
pos.mu    <- grep("mu", parm.names)
pos.sigma <- grep("sigma", parm.names)
PGF <- function(Data) {
# Stick-breaking
V         <- rbeta(Data$H, 1, Data$alpha)
vt        <- log(sd(V))
V[Data$H] <- 1
pi        <- Stick(V)[-(Data$H + 1)]
zeta      <- rcat(Data$n, pi)
mu        <- basemu[zeta]
sigma     <- basesg[zeta]
return(c(vt, mu, sigma))
}
MyData <- list(parm.names=parm.names, mon.names=mon.names,
PGF=PGF, X=x, pos.V=pos.V, pos.mu=pos.mu,
pos.sigma=pos.sigma, H=H, n=n, alpha=alpha)
is.data(MyData)
### Model====
Model <- function(parm, Data){
## Prior parameters
V     <- parm[Data$pos.V]
mu    <- parm[Data$pos.mu]
sigma <- parm[Data$pos.sigma]
#zeta  <- interval(parm[Data$pos.zeta], 1, Data$H)
#parm[Data$pos.zeta] <- zeta
### Log-Priors
v.prior     <- sum(dbeta(exp(V), 1, Data$alpha, log=T))
mu.prior    <- sum(dnorm(mu, 0, 1, log=T))
sigma.prior <- sum(dgamma(exp(sigma), 1e-2, 1e-2, log=T))
#zeta.prior <- sum(dcat(zeta, p=rep(1/length(V), length(V)), log=T))
Lpp     <- v.prior + mu.prior + sigma.prior #+ v.prior + zeta.prior
### Log-Likelihood
LL      <- sum( dnorm(Data$X, mean=mu, sd=exp(sigma), log=T) )
### Log-Posterior
LP <- LL + Lpp
### Estimates
yhat <- rnorm(Data$n, mean=mu, sd=exp(sigma))
### Output
Modelout <- list(LP=LP, Dev=-2*LL, Monitor=LP, yhat=yhat, parm=parm)
return(Modelout)
}
Model <- compiler::cmpfun(Model)
Initial.Values <- GIV(Model, MyData, PGF=T)
is.model(Model, Initial.Values, MyData)
is.bayesian(Model, Initial.Values, MyData)
### Run!====
set.seed(seed)
if (method=="VB") {
Iters=Iters; Smpl=Smpl
Fit <- VariationalBayes(Model=Model, parm=Initial.Values, Data=MyData,
Covar=NULL, Interval=1e-6, Iterations=Iters,
Method="Salimans2", Samples=Smpl, sir=TRUE,
Stop.Tolerance=1e-5, CPUs=CPUs, Type="PSOCK")
} else if (method=="LA") {
Iters=Iters; Smpl=Smpl
Fit <- LaplaceApproximation(Model, parm=Initial.Values, Data=MyData,
Interval=1e-6, Iterations=Iters,
Method="SPG", Samples=Smpl, sir=TRUE,
CovEst="Identity", Stop.Tolerance=1e-5,
CPUs=CPUs, Type="PSOCK")
} else if (method=="MCMC") {
Iters=Iters; Status=Iters/10; Thin=Thin; Ad=A
Fit <- LaplacesDemon(Model=Model, Data=MyData,
Initial.Values=Initial.Values,
Covar=NULL, Iterations=Iters,Status=Status,
Thinning=Thin, Algorithm="NUTS",
Specs=list(A=Ad,delta=0.6,epsilon=NULL,Lmax=Inf))
} else if (method=="PMC") {
Iters=Iters; Smpl=Smpl; Thin=Thin
Fit <- PMC(Model=Model, Data=MyData, Initial.Values=Initial.Values,
Covar=NULL, Iterations=Iters, Thinning=Thin, alpha=NULL,
M=2, N=Smpl, nu=1e3, CPUs=CPUs, Type="PSOCK")
} else if (method=="IQ") {
Iters=Iters; Smpl=Smpl
Fit <- IterativeQuadrature(Model=Model, parm=Initial.Values,
Data=MyData, Covar=NULL,
Iterations=Iters, Algorithm="CAGH",
Specs=list(N=3, Nmax=10, Packages=NULL,
Dyn.libs=NULL),
Samples=Smpl, sir=T,
Stop.Tolerance=c(1e-5,1e-15),
Type="PSOCK", CPUs=CPUs)
} else {stop('Unknown optimization method.')}
### Results====
mu    = Fit$Summary1[grep("mu", rownames(Fit$Summary1), fixed=TRUE),1]
sigma = exp(Fit$Summary1[grep("sigma", rownames(Fit$Summary1), fixed=TRUE),1])
plot(ecdf(mu)(seq(-3,3,len=100)) ~ seq(-3,3,len=100), type="l", ylim=c(0,1))
lines(pnorm(seq(-3,3,len=100)) ~ seq(-3,3,len=100), type="l", lty=2)
lines(ecdf(x)(seq(-3,3,len=100)) ~ seq(-3,3,len=100), type="l", lty=3)
method="LA"; Iters=2000; Smpl=1000; seed=666
set.seed(seed)
x <- rnorm(50)
### Start====
require(LaplacesDemon)
require(compiler)
require(parallel)
require(tidyr)
CPUs = detectCores(all.tests = FALSE, logical = TRUE) - 1
if(CPUs == 0) CPUs = 1
### Assemble data list====
mon.names  <- "LP"
n = length(x)
H = 1000000
basemu = rnorm(H, mean(x), diff(range(x)))
basesg = rnorm(H, sd(x), 5)
alpha = alpha
parm.names <- as.parm.names(list( V=rep(0,1),
mu=rep(0,n),
sigma=rep(0,n) ))
pos.V     <- grep("V", parm.names)
pos.mu    <- grep("mu", parm.names)
pos.sigma <- grep("sigma", parm.names)
PGF <- function(Data) {
# Stick-breaking
V         <- rbeta(Data$H, 1, Data$alpha)
vt        <- log(sd(V))
V[Data$H] <- 1
pi        <- Stick(V)[-(Data$H + 1)]
zeta      <- rcat(Data$n, pi)
mu        <- basemu[zeta]
sigma     <- basesg[zeta]
return(c(vt, mu, sigma))
}
MyData <- list(parm.names=parm.names, mon.names=mon.names,
PGF=PGF, X=x, pos.V=pos.V, pos.mu=pos.mu,
pos.sigma=pos.sigma, H=H, n=n, alpha=alpha)
is.data(MyData)
### Model====
Model <- function(parm, Data){
## Prior parameters
V     <- parm[Data$pos.V]
mu    <- parm[Data$pos.mu]
sigma <- parm[Data$pos.sigma]
#zeta  <- interval(parm[Data$pos.zeta], 1, Data$H)
#parm[Data$pos.zeta] <- zeta
### Log-Priors
v.prior     <- sum(dbeta(exp(V), 1, Data$alpha, log=T))
mu.prior    <- sum(dnorm(mu, 0, 1, log=T))
sigma.prior <- sum(dgamma(exp(sigma), 1e-2, 1e-2, log=T))
#zeta.prior <- sum(dcat(zeta, p=rep(1/length(V), length(V)), log=T))
Lpp     <- v.prior + mu.prior + sigma.prior #+ v.prior + zeta.prior
### Log-Likelihood
LL      <- sum( dnorm(Data$X, mean=mu, sd=exp(sigma), log=T) )
### Log-Posterior
LP <- LL + Lpp
### Estimates
yhat <- rnorm(Data$n, mean=mu, sd=exp(sigma))
### Output
Modelout <- list(LP=LP, Dev=-2*LL, Monitor=LP, yhat=yhat, parm=parm)
return(Modelout)
}
Model <- compiler::cmpfun(Model)
Initial.Values <- GIV(Model, MyData, PGF=T)
is.model(Model, Initial.Values, MyData)
is.bayesian(Model, Initial.Values, MyData)
### Run!====
set.seed(seed)
if (method=="VB") {
Iters=Iters; Smpl=Smpl
Fit <- VariationalBayes(Model=Model, parm=Initial.Values, Data=MyData,
Covar=NULL, Interval=1e-6, Iterations=Iters,
Method="Salimans2", Samples=Smpl, sir=TRUE,
Stop.Tolerance=1e-5, CPUs=CPUs, Type="PSOCK")
} else if (method=="LA") {
Iters=Iters; Smpl=Smpl
Fit <- LaplaceApproximation(Model, parm=Initial.Values, Data=MyData,
Interval=1e-6, Iterations=Iters,
Method="SPG", Samples=Smpl, sir=TRUE,
CovEst="Identity", Stop.Tolerance=1e-5,
CPUs=CPUs, Type="PSOCK")
} else if (method=="MCMC") {
Iters=Iters; Status=Iters/10; Thin=Thin; Ad=A
Fit <- LaplacesDemon(Model=Model, Data=MyData,
Initial.Values=Initial.Values,
Covar=NULL, Iterations=Iters,Status=Status,
Thinning=Thin, Algorithm="NUTS",
Specs=list(A=Ad,delta=0.6,epsilon=NULL,Lmax=Inf))
} else if (method=="PMC") {
Iters=Iters; Smpl=Smpl; Thin=Thin
Fit <- PMC(Model=Model, Data=MyData, Initial.Values=Initial.Values,
Covar=NULL, Iterations=Iters, Thinning=Thin, alpha=NULL,
M=2, N=Smpl, nu=1e3, CPUs=CPUs, Type="PSOCK")
} else if (method=="IQ") {
Iters=Iters; Smpl=Smpl
Fit <- IterativeQuadrature(Model=Model, parm=Initial.Values,
Data=MyData, Covar=NULL,
Iterations=Iters, Algorithm="CAGH",
Specs=list(N=3, Nmax=10, Packages=NULL,
Dyn.libs=NULL),
Samples=Smpl, sir=T,
Stop.Tolerance=c(1e-5,1e-15),
Type="PSOCK", CPUs=CPUs)
} else {stop('Unknown optimization method.')}
### Results====
mu    = Fit$Summary1[grep("mu", rownames(Fit$Summary1), fixed=TRUE),1]
sigma = exp(Fit$Summary1[grep("sigma", rownames(Fit$Summary1), fixed=TRUE),1])
plot(ecdf(mu)(seq(-3,3,len=100)) ~ seq(-3,3,len=100), type="l", ylim=c(0,1))
lines(pnorm(seq(-3,3,len=100)) ~ seq(-3,3,len=100), type="l", lty=2)
lines(ecdf(x)(seq(-3,3,len=100)) ~ seq(-3,3,len=100), type="l", lty=3)
method="LA"; Iters=2000; Smpl=1000; seed=666
#set.seed(seed)
x <- rnorm(50)
### Start====
require(LaplacesDemon)
require(compiler)
require(parallel)
require(tidyr)
CPUs = detectCores(all.tests = FALSE, logical = TRUE) - 1
if(CPUs == 0) CPUs = 1
### Assemble data list====
mon.names  <- "LP"
n = length(x)
H = 1000000
basemu = rnorm(H, mean(x), diff(range(x)))
basesg = rnorm(H, sd(x), 5)
alpha = alpha
parm.names <- as.parm.names(list( V=rep(0,1),
mu=rep(0,n),
sigma=rep(0,n) ))
pos.V     <- grep("V", parm.names)
pos.mu    <- grep("mu", parm.names)
pos.sigma <- grep("sigma", parm.names)
PGF <- function(Data) {
# Stick-breaking
V         <- rbeta(Data$H, 1, Data$alpha)
vt        <- log(sd(V))
V[Data$H] <- 1
pi        <- Stick(V)[-(Data$H + 1)]
zeta      <- rcat(Data$n, pi)
mu        <- basemu[zeta]
sigma     <- basesg[zeta]
return(c(vt, mu, sigma))
}
MyData <- list(parm.names=parm.names, mon.names=mon.names,
PGF=PGF, X=x, pos.V=pos.V, pos.mu=pos.mu,
pos.sigma=pos.sigma, H=H, n=n, alpha=alpha)
is.data(MyData)
### Model====
Model <- function(parm, Data){
## Prior parameters
V     <- parm[Data$pos.V]
mu    <- parm[Data$pos.mu]
sigma <- parm[Data$pos.sigma]
#zeta  <- interval(parm[Data$pos.zeta], 1, Data$H)
#parm[Data$pos.zeta] <- zeta
### Log-Priors
v.prior     <- sum(dbeta(exp(V), 1, Data$alpha, log=T))
mu.prior    <- sum(dnorm(mu, 0, 1, log=T))
sigma.prior <- sum(dgamma(exp(sigma), 1e-2, 1e-2, log=T))
#zeta.prior <- sum(dcat(zeta, p=rep(1/length(V), length(V)), log=T))
Lpp     <- v.prior + mu.prior + sigma.prior #+ v.prior + zeta.prior
### Log-Likelihood
LL      <- sum( dnorm(Data$X, mean=mu, sd=exp(sigma), log=T) )
### Log-Posterior
LP <- LL + Lpp
### Estimates
yhat <- rnorm(Data$n, mean=mu, sd=exp(sigma))
### Output
Modelout <- list(LP=LP, Dev=-2*LL, Monitor=LP, yhat=yhat, parm=parm)
return(Modelout)
}
Model <- compiler::cmpfun(Model)
Initial.Values <- GIV(Model, MyData, PGF=T)
is.model(Model, Initial.Values, MyData)
is.bayesian(Model, Initial.Values, MyData)
### Run!====
set.seed(seed)
if (method=="VB") {
Iters=Iters; Smpl=Smpl
Fit <- VariationalBayes(Model=Model, parm=Initial.Values, Data=MyData,
Covar=NULL, Interval=1e-6, Iterations=Iters,
Method="Salimans2", Samples=Smpl, sir=TRUE,
Stop.Tolerance=1e-5, CPUs=CPUs, Type="PSOCK")
} else if (method=="LA") {
Iters=Iters; Smpl=Smpl
Fit <- LaplaceApproximation(Model, parm=Initial.Values, Data=MyData,
Interval=1e-6, Iterations=Iters,
Method="SPG", Samples=Smpl, sir=TRUE,
CovEst="Identity", Stop.Tolerance=1e-5,
CPUs=CPUs, Type="PSOCK")
} else if (method=="MCMC") {
Iters=Iters; Status=Iters/10; Thin=Thin; Ad=A
Fit <- LaplacesDemon(Model=Model, Data=MyData,
Initial.Values=Initial.Values,
Covar=NULL, Iterations=Iters,Status=Status,
Thinning=Thin, Algorithm="NUTS",
Specs=list(A=Ad,delta=0.6,epsilon=NULL,Lmax=Inf))
} else if (method=="PMC") {
Iters=Iters; Smpl=Smpl; Thin=Thin
Fit <- PMC(Model=Model, Data=MyData, Initial.Values=Initial.Values,
Covar=NULL, Iterations=Iters, Thinning=Thin, alpha=NULL,
M=2, N=Smpl, nu=1e3, CPUs=CPUs, Type="PSOCK")
} else if (method=="IQ") {
Iters=Iters; Smpl=Smpl
Fit <- IterativeQuadrature(Model=Model, parm=Initial.Values,
Data=MyData, Covar=NULL,
Iterations=Iters, Algorithm="CAGH",
Specs=list(N=3, Nmax=10, Packages=NULL,
Dyn.libs=NULL),
Samples=Smpl, sir=T,
Stop.Tolerance=c(1e-5,1e-15),
Type="PSOCK", CPUs=CPUs)
} else {stop('Unknown optimization method.')}
### Results====
mu    = Fit$Summary1[grep("mu", rownames(Fit$Summary1), fixed=TRUE),1]
sigma = exp(Fit$Summary1[grep("sigma", rownames(Fit$Summary1), fixed=TRUE),1])
plot(ecdf(mu)(seq(-3,3,len=100)) ~ seq(-3,3,len=100), type="l", ylim=c(0,1))
lines(pnorm(seq(-3,3,len=100)) ~ seq(-3,3,len=100), type="l", lty=2)
lines(ecdf(x)(seq(-3,3,len=100)) ~ seq(-3,3,len=100), type="l", lty=3)
dev.off()
rm(list=ls())
require(birm)
x <- simRasch(30, 5, 2)
x <- data
x <- simRasch(30, 5, 2)
x <- x$data
fit <- sirm(x)
fit$Fit$Covar
-solve(fit$Fit$Covar)
det(-solve(fit$Fit$Covar))
det(solve(fit$Fit$Covar))
det(-solve(fit$Fit$Covar))
x <- rnorm(100)
y <- (.3 * x) +(sqrt((.7)^2 - 1) * rnorm(100))
y <- (.3 * x) +(sqrt(1 - (.7)^2) * rnorm(100))
cor(x,y)
cbind(x,y)
data <- cbind(x,y)
cor(data)
solve(cor(data))
solve(solve(cor(data)))
det(solve(fit$Fit$Covar))
fit$Fit$LML
fit$Fit$Deviance
mean(fit$Fit$Deviance)/2
mean(fit$Fit$Deviance)/2 + length(parm.name)
x <- simRasch(30, 5, 2)
x <- x$data
mean(fit$Fit$Deviance)/2 + c(ncol(x) + nrow(x))/2 * log((ncol(x) * nrow(x))/(2*pi))
det(solve(fit$Fit$Covar))
solve(fit$Fit$Covar)
image(solve(fit$Fit$Covar))
round(solve(fit$Fit$Covar),4)
?KLD
fit$Fit$Call
fit$Fit$Step.Size.Final
fit$Fit$Deviance
fit$Fit$Converged
fit$Fit$Monitor
fit$Fit$Posterior
### Results====
abil = Fit$Summary1[grep("theta", rownames(Fit$Summary1), fixed=TRUE),1]
diff = Fit$Summary1[grep("b", rownames(Fit$Summary1), fixed=TRUE),1]
fit$Fit$Summary2
fit$Fit$History
G <- fit$Fit$History
G <- fit$Fit$History[1,,]
G
G <- fit$Fit$History[1,1,]
G
G <- fit$Fit$History[,1,]
G
?LaplaceApproximation()
Pred <- predict(fit$Fit, fit$Model, fit$MyData)
Fit <- fit$Fit
### Results====
abil = Fit$Summary1[grep("theta", rownames(Fit$Summary1), fixed=TRUE),1]
diff = Fit$Summary1[grep("b", rownames(Fit$Summary1), fixed=TRUE),1]
Model(c(abil,diff), fit$Data)
fit$Model(c(abil,diff), fit$Data)
fit$Model(c(abil,diff), fit$Data)$yhat
x
as.vector(x)
c(fit$Model(c(abil,diff), fit$Data)$yhat, as.vector(x))
cbind(fit$Model(c(abil,diff), fit$Data)$yhat, as.vector(x))
cbind(ecdf(fit$Model(c(abil,diff), fit$Data)$yhat)(fit$Model(c(abil,diff), fit$Data)$yhat), ecdf(as.vector(x))(as.vector(x)))
?KLD
KLD(ecdf(fit$Model(c(abil,diff), fit$Data)$yhat)(fit$Model(c(abil,diff), fit$Data)$yhat), ecdf(as.vector(x))(as.vector(x)))
predict(fit$Fit)
rm(list=ls())
simData <- function(n=NULL, v=NULL ,l=NULL, p=1, seed=666,
sequence=F, model="rasch", dist="norm",
interaction=F, weight="normal"){
set.seed(seed)
if (model == "rasch") {
source("simRasch.R")
Result <- simRasch(n=n, v=v, l=l, seed=seed, sequence=sequence,
dist=dist, interaction=interaction, weight=weight)
} else if (model == "sirm") {
source("simSirm.R")
Result <- simSirm(n=n, v=v, l=l, seed=seed, sequence=sequence, dist=dist)
} else if (model == "plm") {
source("simPLM.R")
Result <- simPLM(n=n, v=v, l=l, p=p, scaling=scaling,
seed=seed, sequence=sequence, dist=dist)
} else stop("Unknow model :(")
return(Result)
}
x <- simData(20, 5, 2, model="rasch")
x <- simData(20, 5, 2, p=1, model="rasch")
x <- simData(20, 5, 2, p=1, model="plm")
simData <- function(n=NULL, v=NULL ,l=NULL, p=1, scaling=1.7,
seed=666, sequence=F, model="rasch",
dist="norm", interaction=F, weight="normal"){
set.seed(seed)
if (model == "rasch") {
source("simRasch.R")
Result <- simRasch(n=n, v=v, l=l, seed=seed, sequence=sequence,
dist=dist, interaction=interaction, weight=weight)
} else if (model == "sirm") {
source("simSirm.R")
Result <- simSirm(n=n, v=v, l=l, seed=seed, sequence=sequence, dist=dist)
} else if (model == "plm") {
source("simPLM.R")
Result <- simPLM(n=n, v=v, l=l, p=p, scaling=scaling,
seed=seed, sequence=sequence, dist=dist)
} else stop("Unknow model :(")
return(Result)
}
x <- simData(20, 5, 2, p=1, model="plm")
simData <- function(n=NULL, v=NULL ,l=NULL, p=1, scaling=1.7,
seed=666, sequence=F, model="rasch",
dist="norm", interaction=F, weight="normal"){
set.seed(seed)
if (model == "rasch") {
source("simRasch.R")
Result <- simRasch(n=n, v=v, l=l, seed=seed, sequence=sequence,
dist=dist, interaction=interaction, weight=weight)
} else if (model == "sirm") {
source("simSirm.R")
Result <- simSirm(n=n, v=v, l=l, seed=seed, sequence=sequence, dist=dist)
} else if (model == "plm") {
source("simPLM.R")
Result <- simPLM(n=n, v=v, l=l, p=p, scaling=scaling,
seed=seed, sequence=sequence, dist=dist)
} else stop("Unknow model :(")
return(Result)
}
x <- simData(20, 5, 2, p=1, model="plm")
simData <- function(n=NULL, v=NULL ,l=NULL, p=1, scaling=1.7,
seed=666, sequence=F, model="rasch",
dist="norm", interaction=F, weight="normal"){
set.seed(seed)
if (model == "rasch") {
source("simRasch.R")
Result <- simRasch(n=n, v=v, l=l, seed=seed, sequence=sequence,
dist=dist, interaction=interaction, weight=weight)
} else if (model == "sirm") {
source("simSirm.R")
Result <- simSirm(n=n, v=v, l=l, seed=seed, sequence=sequence, dist=dist)
} else if (model == "plm") {
source("simPLM.R")
Result <- simPLM(n=n, v=v, l=l, p=p, scaling=scaling,
seed=seed, sequence=sequence, dist=dist)
} else stop("Unknow model :(")
return(Result)
}
x <- simData(20, 5, 2, p=1, model="plm")
x <- simData(20, 5, 2, p=2, model="plm")
x <- simData(20, 5, 2, p=3, model="plm")
x <- simData(20, 5, 2, p=4, model="plm")
x <- simData(20, 5, 2, p=4, model="sirm")
simData <- function(n=NULL, v=NULL ,l=NULL, p=1, scaling=1.7,
seed=666, sequence=F, model="rasch",
dist="norm", interaction=F, weight="normal"){
set.seed(seed)
if (model == "rasch") {
source("simRasch.R")
Result <- simRasch(n=n, v=v, l=l, seed=seed, sequence=sequence,
dist=dist, interaction=interaction, weight=weight)
} else if (model == "sirm") {
source("simSirm.R")
Result <- simSirm(n=n, v=v, l=l, seed=seed, sequence=sequence, dist=dist)
} else if (model == "plm") {
source("simPLM.R")
Result <- simPLM(n=n, v=v, l=l, p=p, scaling=scaling,
seed=seed, sequence=sequence, dist=dist)
} else stop("Unknow model :(")
return(Result)
}
x <- simData(20, 5, 2, p=4, model="sirm")
x <- simData(20, 5, 2, model="sirm")
x
x <- simData(20, 5, 2, interaction=F, model="rasch")
x <- simData(20, 5, 2, interaction=T, model="rasch")
x <- simData(20, 5, 2, model="sirm", dist="beta")
x <- simData(20, 5, 2, model="sirm", dist="beta", sequence=T)
x <- simData(20, 5, 2, model="sirm", dist="beta", sequence=F)
x <- simData(20, 5, 2, model="sirm", dist="beta", sequence=F, seed=1)
x <- simData(20, 5, 2, model="sirm", dist="beta", sequence=F, seed=2)
x <- simData(20, 5, 2, model="sirm", dist="beta", sequence=F, seed=3)
x <- simData(20, 5, 2, model="sirm", dist="beta", sequence=F, seed=4)
x <- simData(20, 5, 2, model="sirm", dist="beta", sequence=F, seed=5)
x <- simData(20, 5, 2, model="sirm", dist="beta", sequence=F, seed=6)
x <- simData(20, 5, 2, model="sirm", dist="beta", sequence=F, seed=7)
x <- simData(20, 5, 2, model="sirm", dist="beta", sequence=F, seed=8)
x <- simData(100, 10, 2, model="sirm", dist="beta", sequence=F, seed=8)
x <- simData(100, 10, 2, model="sirm", dist="beta", sequence=F, seed=1)
x <- simData(100, 10, 2, model="sirm", dist="beta", sequence=F, seed=2)
x
rm(list=ls())
